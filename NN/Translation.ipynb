{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mlukan/GDA3B2021/blob/main/NN/Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAgbCF4OFgv9"
   },
   "source": [
    "### Introduction\n",
    "In this exercise you will build three (optionally four) different networks to experiment with one of the applications of recurrent neural networks called Machine Translation. The preprocessing pipeline that prepares the input data for feeding into the neural network models is provided to you. Therefore, in this excercise you focus on building and experimenting with different network architectures. \n",
    "\n",
    "Optional: To learn more about recurrent neural networks (such as RNN, GRU, and LSTM) their architectures, the differences between them and their applications you can watch this free tutorial: [Sequences and Recurrent networks Tutorial](https://www.youtube.com/watch?v=87kLfzmYBy8&ab_channel=DeepMind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MGrOSRpUxG9L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may want to upgrade the tensorflow package to the latest verion (currently version 2.3) if you have the proper infrastructure\n",
    "# !pip install --upgrade tensorflow\n",
    "import tensorflow\n",
    "tensorflow.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMzRkuZbgt3k"
   },
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fobJjbQhBuju",
    "outputId": "372f5437-ce3f-44a1-d78e-acaf82741832"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get access to a GPU instance you can use the `change runtime type` and set the option to `GPU` from the `Runtime` tab  in the notebook\n",
    "# Checking the GPU availability for the notebook\n",
    "import tensorflow\n",
    "tensorflow.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cD0z5tl4dVOM"
   },
   "outputs": [],
   "source": [
    "# import collection\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu1mXD8unuu9"
   },
   "source": [
    "### Loading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPqbg_C09G6s"
   },
   "source": [
    "#### Reading CSV data files as a list of strings, where each string represents a single line from the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CHuc68kPoSqo"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import TextIOWrapper, BytesIO\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGBtz_Lt39XM",
    "outputId": "a3c11f7e-26da-4e21-bc90-1c788f0f09eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English text samples: ['new jersey is sometimes quiet during autumn , and it is snowy in april .', 'the united states is usually chilly during july , and it is usually freezing in november .']\n"
     ]
    }
   ],
   "source": [
    "path=\"https://github.com/mlukan/GDA3B2021/raw/main/files/\"\n",
    "r = requests.get(path+'small-vocab-en.csv.zip')\n",
    "    \n",
    "with ZipFile(io.BytesIO(r.content))  as zf:\n",
    "    with zf.open('small_vocab_en.csv', 'r') as infile:\n",
    "            reader = csv.reader(TextIOWrapper(infile, 'utf-8'), delimiter='\\n' )\n",
    "            english_text = [item for sublist in reader for item in sublist]\n",
    "            print(f\"English text samples: {english_text[0:2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vVS_nH-4y6J",
    "outputId": "a1e3d080-241d-4f4f-c750-ae7819dc3b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French translation text samples: [\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\", 'les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .']\n"
     ]
    }
   ],
   "source": [
    "path=\"https://github.com/mlukan/GDA3B2021/raw/main/files/\"\n",
    "r = requests.get(path+'small-vocab-fr.csv.zip')\n",
    "with ZipFile(io.BytesIO(r.content)) as zf:\n",
    "    with zf.open('small_vocab_fr.csv', 'r') as infile:\n",
    "        reader = csv.reader(TextIOWrapper(infile, 'utf-8'), delimiter='\\n' )\n",
    "        french_text = [item for sublist in reader for item in sublist]\n",
    "        print(f\"French translation text samples: {french_text[0:2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j5y0rPhaH66T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137860 137860\n",
      "8947407 9709204\n"
     ]
    }
   ],
   "source": [
    "# TODO: Data exploration -> calculate and print some statistics on data\n",
    "print(len(english_text),len(french_text))\n",
    "eng_wordlist= ' '.join(english_text).split(' ')\n",
    "fr_wordlist = ' '.join(french_text).split(' ')\n",
    "print(len(''.join(english_text)),len(''.join(french_text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dictionary with words as keys and zero values from a set of all the words in the english text\n",
    "eng_dict={k:0 for k in set(eng_wordlist)}\n",
    "# Fill the english wordcount dictionary \n",
    "for w in eng_wordlist:\n",
    "    eng_dict[w]+=1\n",
    "# Create a dataframe, sort by count and plot a frequency histogram of the 20 most frequent words\n",
    "eng_df=pd.DataFrame.from_dict(eng_dict, orient='index',columns=['word'])\n",
    "eng_df.sort_values(by='word',ascending=False).iloc[:20,].plot.bar();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fr_dict = {k:0 for k in set(fr_wordlist)}\n",
    "for w in fr_wordlist:\n",
    "    fr_dict[w]+=1\n",
    "fr_df=pd.DataFrame.from_dict(fr_dict, orient='index',columns=['word'])\n",
    "fr_df.sort_values(by='word',ascending=False).iloc[:20,].plot.bar();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ8zEtacK08P"
   },
   "source": [
    "#### Tokenizing the data\n",
    "\n",
    "Since the input data to neural networks needs to be in numerical format, we first turn each sentence into a sequence of word ids using `Tokenizer` function from Keras. Word ids are numerical presentations for words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6s5iwnMKzT4",
    "outputId": "a9e7c9c1-f60c-4514-fdd7-fda9be0f2490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x: List[str]):\n",
    "  \"\"\"Tokenizes sentences into word ids.\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "\n",
    "  \"\"\"\n",
    "  tokenizer=Tokenizer()\n",
    "  tokenizer.fit_on_texts(x)\n",
    "  t=tokenizer.texts_to_sequences(x)\n",
    "  return t, tokenizer\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfffhgywsXMN"
   },
   "source": [
    "#### Padding Sequences\n",
    "\n",
    "To be able to batch the sequences of word ids together, all sequences need to be of the same length. Therefore, as a second preprocessing step we make sure that all the English sentences have the same length as their respective French translations using `pad_sequence` function form Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsB7MNttVYVS",
    "outputId": "cc3f9dbd-26fc-4ccb-ab7b-290032404415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    padding=pad_sequences(x,padding='post',maxlen=length)\n",
    "    return padding\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzZF_s8TuGqw"
   },
   "source": [
    "#### Preprocessing Pipeline\n",
    "\n",
    "As mentioned in the introduction section in this excercise your focus is on building different recurrent neural network architectures. Threfore, in the following cell we provide you with a preprocessing pipeline. You can apply this function to the input data to prepare the data for using in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B158-HbGqMwd",
    "outputId": "8ca482b1-5e3b-48f3-da1d-aa6176301c22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data Info\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 344\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "     Preprocess input (x) and target (y)\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_text, french_text)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Preprocessed Data Info')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137860, 21, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_english_sentences.shape\n",
    "preproc_french_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_fCUxliHXwO"
   },
   "source": [
    "### Models\n",
    "\n",
    "In this section we ask you to build and train Three (optionally four) different neural networks and use them to predict the French Translation of the English sentences.\n",
    "\n",
    "Make use of the `logits_to_text()` function to transform the logits from output of your networks to a French translation. This helps you to better understand the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2CrRvXm91nhd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhYC7lJmxpdd"
   },
   "source": [
    "#### Model 1: Implement a simple RNN network and train the network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_VcO7xkUlJyU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137860, 15, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_english_sentences=preproc_english_sentences.reshape(preproc_english_sentences.shape[0],preproc_english_sentences.shape[1],1)\n",
    "preproc_english_sentences.shape\n",
    "preproc_french_sentences=preproc_french_sentences.reshape(preproc_french_sentences.shape[0],preproc_french_sentences.shape[1],1)\n",
    "preproc_english_sentences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x=pad(preproc_english_sentences,max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1),preproc_french_sentences.shape[-2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137860, 21, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JQB93125ldUo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 21, 100)           30900     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 21, 21)            2121      \n",
      "=================================================================\n",
      "Total params: 33,021\n",
      "Trainable params: 33,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of 260 which is outside the valid range of [0, 21).  Label values: 4 32 31 1 12 63 37 11 46 6 3 95 2 49 0 0 0 0 0 0 0 260 122 40 109 10 23 156 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 90 1 40 16 10 23 14 5 10 38 1 20 23 14 0 0 0 0 0 0 7 33 1 8 66 2 51 6 3 1 8 67 2 47 0 0 0 0 0 0 0 11 30 1 8 60 2 49 5 3 1 58 2 53 0 0 0 0 0 0 0 0 62 1 12 18 2 41 6 3 1 9 59 2 44 0 0 0 0 0 0 0 0 4 32 31 1 9 22 102 2 41 6 3 1 9 18 2 51 0 0 0 0 0 36 1 9 26 63 2 51 5 3 1 19 2 48 0 0 0 0 0 0 0 0 7 87 1 20 16 17 13 5 10 85 1 64 13 140 0 0 0 0 0 0 0 11 30 1 12 59 2 51 6 3 1 9 18 26 11 24 0 0 0 0 0 0 1 3 223 2 62 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 94 4 28 4 73 6 28 76 0 0 0 0 0 0 0 0 0 0 0 0 27 1 234 2 30 2 41 142 0 0 0 0 0 0 0 0 0 0 0 0 0 10 82 1 39 13 14 108 96 5 7 83 1 61 13 14 0 0 0 0 0 0 84 1 64 16 10 23 119 5 7 89 1 39 23 14 0 0 0 0 0 0 0 4 32 31 1 19 2 43 5 3 1 8 92 2 48 0 0 0 0 0 0 0 106 128 91 28 76 4 71 6 4 72 0 0 0 0 0 0 0 0 0 0 0 4 32 31 1 8 137 2 54 5 3 1 69 21 2 43 0 0 0 0 0 0 7 33 1 12 66 2 54 5 3 1 21 26 11 24 0 0 0 0 0 0 0 36 1 9 19 2 49 6 3 1 69 21 2 43 0 0 0 0 0 0 0 0 7 89 1 20 16 17 5 10 82 1 40 93 0 0 0 0 0 0 0 0 0 29 1 8 57 37 11 44 5 3 1 12 67 2 51 0 0 0 0 0 0 0 106 128 91 4 28 4 75 6 4 70 0 0 0 0 0 0 0 0 0 0 0 7 33 1 104 37 11 46 6 3 1 9 60 2 41 0 0 0 0 0 0 0 62 1 12 66 15 25 22 45 5 3 1 8 57 2 52 0 0 0 0 0 0 27 100 4 72 4 73 6 4 75 0 0 0 0 0 0 0 0 0 0 0 0 10 38 1 20 13 14 108 96 5 84 1 64 13 14 0 0 0 0 0 0 0 231 106 46 26 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 99 124 4 74 4 77 6 4 70 0 0 0 0 0 0 0 0 0 0 0 0 62 1 18 26 98 6 3 1 9 68 2 46 0 0 0 0 0 0 0 0 0 3 100 4 75 4 73 6 4 72 0 0 0 0 0 0 0 0 0 0 0 0 62 1 9 26 63 2 43 5 3 1 8 92 2 46 0 0 0 0 0 0 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-35-fde6edaa5a46>:42) ]] [Op:__inference_train_function_27600]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fde6edaa5a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                   metrics=['accuracy'])\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreproc_french_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;31m# TODO: Train the network you built in rnn_model. What size do you choose for the epochs, batch_size and validation_split?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 260 which is outside the valid range of [0, 21).  Label values: 4 32 31 1 12 63 37 11 46 6 3 95 2 49 0 0 0 0 0 0 0 260 122 40 109 10 23 156 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 90 1 40 16 10 23 14 5 10 38 1 20 23 14 0 0 0 0 0 0 7 33 1 8 66 2 51 6 3 1 8 67 2 47 0 0 0 0 0 0 0 11 30 1 8 60 2 49 5 3 1 58 2 53 0 0 0 0 0 0 0 0 62 1 12 18 2 41 6 3 1 9 59 2 44 0 0 0 0 0 0 0 0 4 32 31 1 9 22 102 2 41 6 3 1 9 18 2 51 0 0 0 0 0 36 1 9 26 63 2 51 5 3 1 19 2 48 0 0 0 0 0 0 0 0 7 87 1 20 16 17 13 5 10 85 1 64 13 140 0 0 0 0 0 0 0 11 30 1 12 59 2 51 6 3 1 9 18 26 11 24 0 0 0 0 0 0 1 3 223 2 62 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 94 4 28 4 73 6 28 76 0 0 0 0 0 0 0 0 0 0 0 0 27 1 234 2 30 2 41 142 0 0 0 0 0 0 0 0 0 0 0 0 0 10 82 1 39 13 14 108 96 5 7 83 1 61 13 14 0 0 0 0 0 0 84 1 64 16 10 23 119 5 7 89 1 39 23 14 0 0 0 0 0 0 0 4 32 31 1 19 2 43 5 3 1 8 92 2 48 0 0 0 0 0 0 0 106 128 91 28 76 4 71 6 4 72 0 0 0 0 0 0 0 0 0 0 0 4 32 31 1 8 137 2 54 5 3 1 69 21 2 43 0 0 0 0 0 0 7 33 1 12 66 2 54 5 3 1 21 26 11 24 0 0 0 0 0 0 0 36 1 9 19 2 49 6 3 1 69 21 2 43 0 0 0 0 0 0 0 0 7 89 1 20 16 17 5 10 82 1 40 93 0 0 0 0 0 0 0 0 0 29 1 8 57 37 11 44 5 3 1 12 67 2 51 0 0 0 0 0 0 0 106 128 91 4 28 4 75 6 4 70 0 0 0 0 0 0 0 0 0 0 0 7 33 1 104 37 11 46 6 3 1 9 60 2 41 0 0 0 0 0 0 0 62 1 12 66 15 25 22 45 5 3 1 8 57 2 52 0 0 0 0 0 0 27 100 4 72 4 73 6 4 75 0 0 0 0 0 0 0 0 0 0 0 0 10 38 1 20 13 14 108 96 5 84 1 64 13 14 0 0 0 0 0 0 0 231 106 46 26 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 99 124 4 74 4 77 6 4 70 0 0 0 0 0 0 0 0 0 0 0 0 62 1 18 26 98 6 3 1 9 68 2 46 0 0 0 0 0 0 0 0 0 3 100 4 75 4 73 6 4 72 0 0 0 0 0 0 0 0 0 0 0 0 62 1 9 26 63 2 43 5 3 1 8 92 2 46 0 0 0 0 0 0 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-35-fde6edaa5a46>:42) ]] [Op:__inference_train_function_27600]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Model 1: simple RNN model\n",
    "def rnn_model(input_shape, output_sequence_length, english_vocab_size,french_vocab_size): #, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Build the layers and compile the model. (Hint: Use a GRU network followed by a TimeDistributed dense layer from tensorflow.keras.layers module)\n",
    "    '''    \n",
    "    from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "    from tensorflow.keras.layers import Embedding\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape[1:]))\n",
    "    model.add(GRU(english_vocab_size,return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "    \n",
    "\n",
    "    model.summary()\n",
    "        # What is the input shape of your model? Which activation function do you choose for the dense layer?   \n",
    "    return model\n",
    "\n",
    "        # Hyperparameters\n",
    "    \n",
    "    # TODO: Build the layers\n",
    " \n",
    "    # Compile model\n",
    " \n",
    "\n",
    "model = rnn_model(tmp_x.shape,max_french_sequence_length,english_vocab_size+1,french_vocab_size+1) \n",
    "# TODO: Preprocess and reshape the input to work with a basic RNN. (Hint: Use preproc_english_sentences, preproc_french_sentences and reshape function from keras)\n",
    "learning_rate = 0.003\n",
    "\n",
    "model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "hist=model.fit(tmp_x,preproc_french_sentences)\n",
    "# TODO: Train the network you built in rnn_model. What size do you choose for the epochs, batch_size and validation_split?\n",
    "\n",
    "# TODO: Print prediction(s) for one or more of the English sentences. Hint: Make use of the `logits_to_text` function for transforming output logits to text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQacJtFZ3Zic"
   },
   "source": [
    "#### Model 2: Implement an RNN model using word embeddings\n",
    "\n",
    "Embeddings are better representation of words. An embedding is a vector representation of a word in n-dimensional space, where n represents the size of the embedding vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ropzm7KD8juF"
   },
   "outputs": [],
   "source": [
    "# Model 2: Embedding\n",
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Build the layers and compile the model. (Hint: Similar to the first model use a GRU network followed by a TimeDistributed dense layer from tensorflow.keras.layers module. \n",
    "    # And this time make use of Embedding as well!)\n",
    "    # What is the input shape of your model? Which activation function do you choose for the dense layer?\n",
    "\n",
    "    return model\n",
    "\n",
    "# TODO: Preprocess and reshape the input to work with a basic RNN. (Hint: Use preproc_english_sentences, preproc_french_sentences and reshape function from keras)\n",
    "\n",
    "# TODO: Train the network you built in rnn_model. What size do you choose for the epochs, batch_size and validation_split?\n",
    "\n",
    "# TODO: Print prediction(s) for one or more of the English sentences. Hint: Make use of the `logits_to_text` function for transforming output logits to text. \n",
    "# (Hint: If you predict on the same sentence you can compare the result of different model on that specific sentence with each other.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqMHh7Hw3X_z"
   },
   "source": [
    "#### Model 3: Implement a Bidirectional RNN network.\n",
    "\n",
    "One of the restrictions of RNN networks is that they only see the data from past. However, Bidirectional RNNs can see the data in both directions past and future. Make use of Bidirectionality and experiment if this feature enhances your network's performance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_ZqZ7PqEWSM"
   },
   "outputs": [],
   "source": [
    "# Model 3: Bidirectional RNNs\n",
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO:  Build the layers and compile the model. (Hint: Similar to the first model use a GRU network followed by a TimeDistributed dense layer from tensorflow.keras.layers module. \n",
    "    # Don't forget to make your network bidirectional!)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# TODO: Print prediction(s) for one or more of the English sentences. Hint: Make use of the `logits_to_text` function for transforming output logits to text.\n",
    "# (Hint: If you predict on the same sentence you can compare the result of different model on that specific sentence with each other.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVgbz1IGLbTn"
   },
   "source": [
    "#### Model 4: Implement an Encoder-Decoder model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qgj43NvjKZDO"
   },
   "outputs": [],
   "source": [
    "\n",
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # OPTIONAL: Implement\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# OPTIONAL: Train and Print prediction(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63Z7VO2cNHSD"
   },
   "source": [
    "#### Finally, you can use all the models you built in this exercise to create a model that incorporates embedding and bidirectionality into one model. (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54Mj9eDjMDwX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "\n",
    "    return model\n",
    "# OPTIONAL: Train and Print prediction(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiXZThFkN07F"
   },
   "source": [
    "### Final Notes and TODOs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   In this exercise we focus on  learning different recurrent network architectures for machine translation, However we don't evaluate the models on a separate test set. To follow best machine learning practices, you can make use of the `sklearn.model_selecttion.train_test_split()` function to create separate training and test datasets. You can then retrain each of the models on the training set and evaluate the prediction accuracy using the hold out set. Observe how the best model performance might change.\n",
    "* If you don't have any idea about French (like me :D) you can use a translater like [google translat](https://translate.google.com/) to compare the prediction(s) from your models with the respective original English sentence(s).\n",
    "*   TODO: Finally, you can also try to train and predict your models on other language pairs. As a convenient example, you can use your models to translate from French to English since you already have the data available.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Kopie von Translation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
