{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mlukan/GDA3B2021/blob/main/NN/Stock_Prediction_Quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otl-MXUqPWAs"
   },
   "source": [
    "### Introduction \n",
    "In this exercise you will work with stock market data. We use the data available at [Yahoo Finance](https://finance.yahoo.com/quote/DAX/history?period1=1478390400&period2=1604534400&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true)\n",
    "You will build sequential models to predict the variations for Global X DAX Germany ETF (DAX). The goal is to predict whether the stock value is higher or lower than its actual value of previous day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "XHfBtj1tloYy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9DlO6aW6fOB"
   },
   "source": [
    "### Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pY8H6OBu6Z-F",
    "outputId": "fcce7b48-600b-4b19-ddae-ce55872f5f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data column info:\n",
      " date          object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "adj_close    float64\n",
      "volume         int64\n",
      "dtype: object\n",
      "Training data shape is (644, 7)\n"
     ]
    }
   ],
   "source": [
    "# Loading training data\n",
    "#training_data = pd.read_csv(\"https://github.com/mlukan/GDA3B2021/tree/main/daxdata/dax_train_2019.csv.txt\", sep=\",\")\n",
    "training_data = pd.read_csv(\"../daxdata/dax_train_2019.csv.txt\", sep=\",\")\n",
    "\n",
    "print(f\"Training data column info:\\n {training_data.dtypes}\")\n",
    "print(f\"Training data shape is {training_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpILl8NTZ2SW",
    "outputId": "90c73a06-fa34-4b6d-e9ca-2efb2cb5e122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data column info:\n",
      " date          object\n",
      "open         float64\n",
      "high         float64\n",
      "Low          float64\n",
      "close        float64\n",
      "adj_close    float64\n",
      "volume         int64\n",
      "dtype: object\n",
      "Testing data shape is (148, 7)\n"
     ]
    }
   ],
   "source": [
    "# Loading testing data\n",
    "#testing_data = pd.read_csv(\"https://github.com/mlukan/GDA3B2021/tree/main/daxdata/dax_test_2019.csv.txt\", sep=\",\")\n",
    "testing_data = pd.read_csv(\"../daxdata/dax_test_2019.csv.txt\", sep=\",\")\n",
    "\n",
    "print(f\"Testing data column info:\\n {testing_data.dtypes}\")\n",
    "print(f\"Testing data shape is {testing_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKR-Y1L2-Bz4",
    "outputId": "3a6c3838-7eff-4bea-81fd-648616f521dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_data)\n",
    "testing_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEGwqlyPyku7"
   },
   "source": [
    "####  Are there any NaN values in training and testing data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muZCsfzYYXiP",
    "outputId": "18da8629-f6b7-46c9-a572-30cd4f2cde20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in training data columns:\n",
      "date         0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "adj_close    0\n",
      "volume       0\n",
      "dtype: int64\n",
      "Number of NaNs in testing data columns:\n",
      "date         0\n",
      "open         0\n",
      "high         0\n",
      "Low          0\n",
      "close        0\n",
      "adj_close    0\n",
      "volume       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_count_nan = training_data.shape[0] - training_data.count()\n",
    "testing_count_nan = testing_data.shape[0] - testing_data.count()\n",
    "print(f\"Number of NaNs in training data columns:\\n{training_count_nan}\")\n",
    "print(f\"Number of NaNs in testing data columns:\\n{testing_count_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "T4XpSecTv3u0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 7)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMDCQsRH0xsV"
   },
   "source": [
    "#### Preprocessing the data, extracting the features, and normalising the features using `preprocessing.MinMaxScaler` function from sklearn\n",
    "\n",
    "We have provided you with the relevant function here. But we expect you to explore the data generated. \n",
    "\n",
    "What are the shapes?\n",
    "\n",
    "Do a test whether features and labels correspond, i.e. whether the label for each sequence is the value following that sequence? \n",
    "\n",
    "Optional: Extend the function to include more features - and change it \n",
    "to choose a different column as target, i.e. adj_close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqrdEVIiFPWN"
   },
   "outputs": [],
   "source": [
    "# Limiting the training and testing data to \"open\" column \n",
    "training_data_processed = training_data.iloc[:, 1:2].values\n",
    "testing_data_processed = testing_data.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g8bFN1AvjXA1"
   },
   "outputs": [],
   "source": [
    "def create_features_labels(training_data, testing_data, scaler=MinMaxScaler(feature_range = (0, 1)), sequence_length=60):\n",
    "    \"\"\"\n",
    "    Create feature and labels from training data\n",
    "    :param training_data\n",
    "    :param testing_data\n",
    "    :param sequence_length\n",
    "    :param scaler\n",
    "    :return: Features and labels sets, and labels bins\n",
    "    \"\"\"\n",
    "    features_set = []\n",
    "    labels = []\n",
    "    labels_bin = []\n",
    "    test_features = []\n",
    "    # Limiting the training and testing data to relevant column (here \"open\" column)\n",
    "    training_data_processed = training_data.iloc[:, 1:2].values\n",
    "    # Normalization: Transform features by scaling each feature in training to be in a range of (0, 1)\n",
    "    training_data_processed = scaler.fit_transform(training_data_processed)\n",
    "    # Preparing training data features and labels\n",
    "    for i in range(sequence_length, len(training_data)):\n",
    "        features_set.append(training_data_processed[i-sequence_length:i, 0])\n",
    "        labels.append(training_data_processed[i, 0])\n",
    "        # Fill binary labels\n",
    "        if training_data_processed[i,0] > training_data_processed[i-1,0]:\n",
    "            labels_bin.append(1)\n",
    "        else:\n",
    "            labels_bin.append(0)\n",
    "    # Preparing the testing data features\n",
    "    total = pd.concat((training_data['open'], testing_data['open']), axis=0)\n",
    "    test_inputs = total[len(total) - len(testing_data) - sequence_length:].values\n",
    "    test_inputs = test_inputs.reshape(-1,1)\n",
    "    test_inputs = scaler.transform(test_inputs)\n",
    "\n",
    "    for i in range(sequence_length, len(test_inputs)):\n",
    "        test_features.append(test_inputs[i-sequence_length:i, 0])\n",
    "    \n",
    "    test_features = np.array(test_features)\n",
    "    test_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))\n",
    "    features_set, labels, labels_bin = np.array(features_set), np.array(labels), np.array(labels_bin)\n",
    "    return np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1)), labels, labels_bin, test_features, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EVe5xtf5A_Mf"
   },
   "outputs": [],
   "source": [
    "features_set, labels, labels_bin, test_features, scaler = create_features_labels(training_data, testing_data, MinMaxScaler(feature_range = (0, 1)), 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ffn2FwPywslN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_set (584, 60, 1)\n",
      "labels (584,)\n",
      "labels_bin (584,)\n",
      "test_features (148, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "# What are the shapes?\n",
    "for f in ['features_set', 'labels', 'labels_bin', 'test_features']:\n",
    "    print(f,eval(f+\".shape\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Do a test whether features and labels correspond, i.e. whether the label for each sequence is the value following that sequence? \n",
    "ct=0\n",
    "for f, l in  zip(features_set[1:,-1].flatten(),labels):\n",
    "    if ct <10:\n",
    "        print(f,l)\n",
    "        ct+=1\n",
    "    if f!=l:\n",
    "        print(f,l,\"does not match\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_bin=labels_bin.reshape(labels_bin.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXPt3xbzTOfz"
   },
   "source": [
    "### Model\n",
    "In this section we ask you to build and train a LSTM neural network and use it predict the stock price variations on your testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "5hJ3Y27DTPtk"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "def lstm_model(input_shape):\n",
    "    batch_size = 8 \n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(7))  \n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(loss = 'mean_squared_error', optimizer = \"adam\", metrics=['mse'])\n",
    "\n",
    "# Training\n",
    "\n",
    "    # TODO: Implement your model here. \n",
    "    # (Hint: Make use of `Sequential` function from tensorflow.keras to group a linear stack of layers into the model. In addition, \n",
    "    # you can apply droupouts to your input using `Dropout` from tensorflow.keras.layers)\n",
    "    return lstm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "O1hqgDfwzP9X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:663 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1108 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:862 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:645 get_initial_state\n        init_state = get_initial_state_fn(\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2523 get_initial_state\n        return list(_generate_zero_filled_state_for_cell(\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2968 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2984 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:635 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:635 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2981 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2747 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2794 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2732 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:845 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_3/lstm_3/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-b7001930721a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:663 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1108 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:862 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:645 get_initial_state\n        init_state = get_initial_state_fn(\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2523 get_initial_state\n        return list(_generate_zero_filled_state_for_cell(\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2968 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2984 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:635 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:635 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2981 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2747 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2794 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2732 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/A19893678/local/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:845 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_3/lstm_3/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#batch_size\n",
    "lstm=lstm_model(features_set.shape)\n",
    "lstm.fit(features_set, labels, batch_size=8, epochs=10, verbose=1)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOOzJMNVUPf6"
   },
   "source": [
    "Compile your model, train it and evaluate it. \n",
    "\n",
    "What is your mse - and what is your accuracy (note that you have two different types of labels readily available to you). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2J9-MZwszQrz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZd98OTBzQ4R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpnWTNN4zQ8J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiTrCOSqzRrE"
   },
   "source": [
    "Optional: Try your model with more features, try with different sequence lengths (this is a hyperparameter) - and try with the \"real\" Dax Performance Index data also provided (which reaches back longer). If you do so, you will have to split the data into training and test sets first). "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Stock_Prediction_Quest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
